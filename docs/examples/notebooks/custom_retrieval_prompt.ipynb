{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using a custom retrieval prompt and evaluating the results with** `ir-measures`\n",
    "`ir-measures` is a library that provides a common interface to many Information Retrieval evaluation tools, such as [`pytrec-eval`](https://github.com/terrierteam/pytrec_eval) and [Ranx](https://github.com/AmenRa/ranx).\n",
    "\n",
    "This notebook will show how to use a custom prompt with RAGElo's `CustomPromptEvaluator` to evaluate documents retrieved by a search system and use the annotations generated by the LLM as the relevants to measure the performance of the retrieval pipeline with `ir-measures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://zeta-alpha:****@pypi.zeta-alpha.com\n",
      "Collecting ir-measures\n",
      "  Downloading ir_measures-0.3.3.tar.gz (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytrec-eval-terrier>=0.5.5 in /Users/acamara/.pyenv/versions/3.8.17/envs/ragelo38/lib/python3.8/site-packages (from ir-measures) (0.5.6)\n",
      "Collecting cwl-eval>=1.0.10\n",
      "  Downloading cwl-eval-1.0.12.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/acamara/.pyenv/versions/3.8.17/envs/ragelo38/lib/python3.8/site-packages (from cwl-eval>=1.0.10->ir-measures) (1.24.4)\n",
      "Installing collected packages: cwl-eval, ir-measures\n",
      "\u001b[33m  DEPRECATION: cwl-eval is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for cwl-eval ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  DEPRECATION: ir-measures is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for ir-measures ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed cwl-eval-1.0.12 ir-measures-0.3.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ir-measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages and prepare evaluators\n",
    "\n",
    "As we are using the `CustomPromptEvaluator` retrieval evaluator, we will provide it with our own prompt, as well as the configurations needed to build build the prompts properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragelo import Query, Document, get_retrieval_evaluator, get_llm_provider\n",
    "\n",
    "llm_provider = get_llm_provider(\"openai\", model_name=\"gpt-4o-mini\", max_tokens=2048)\n",
    "\n",
    "prompt = \"\"\"\"\n",
    "You are an expert annotator for a search engine, rating the relevance of \\\n",
    "search results to a given query submitted by a user.\n",
    "\n",
    "Given a user query, you should provide a relevance score on an integer \\\n",
    "scale from 0 to 3, with the following meanings:\n",
    "\n",
    "0: The document is not relevant to the query.\n",
    "1: The document is slightly relevant to the query.\n",
    "2: The document is relevant to the query, but doesn't cover all aspects of it.\n",
    "3: The document is highly relevant to the query and completely fulfills the user's information needs.\n",
    "\n",
    "Assume that you are writing a report on the subject of the topic. If you would \\\n",
    "not use any of the information contained in the document in such a report, but \\\n",
    "the document still covers the right topic, mark it 1. \\\n",
    "If you would use any of the information contained in the document in such a report, mark it 2\n",
    "If the document is primarily about the topic, or contains vital information about \\\n",
    "the topic, mark it 3. Otherwise, mark it 0.\n",
    "\n",
    "# Query\n",
    "{query}\n",
    "\n",
    "# Retrieved document\n",
    "{document}\n",
    "\n",
    "# Instructions\n",
    "\n",
    "Think step by step about how you would evaluate the relevance of the document to the query. \\\n",
    "Your output should be a JSON dictionary with two keys: \"relevance\" and \"explanation\". \\\n",
    "The \"relevance\" key should contain the integer relevance score. \\\n",
    "The \"explanation\" key should contain a string explaining why you rated the document as you did. \\\n",
    "\"\"\"\n",
    "\n",
    "evaluator = get_retrieval_evaluator(\n",
    "    \"custom_prompt\",\n",
    "    llm_provider=llm_provider,\n",
    "    prompt=prompt,\n",
    "    answer_format_retrieval_evaluator=\"multi_field_json\", # We are asking the result to be returned as JSON object with multiple fields, and we are interested in all of them.\n",
    "    scoring_keys_retrieval_evaluator=[\"relevance\", \"explanation\"], # These are the keys that we are interested in.\n",
    "    n_processes=20,  # How many threads to use when evaluating the retrieved documents. Will do that many parallel calls to OpenAI.\n",
    "    rich_print=True,  # Wether or not to use rich to print colorful outputs.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the queries and the documents to evaluate\n",
    "We are using queries and document examples from the [SciRepEval dataset](https://huggingface.co/datasets/allenai/scirepeval/viewer/search/train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = Query(qid=\"query_1\", query=\"bumble bee homeotic shift\")\n",
    "\n",
    "\n",
    "# Add some documents retrieved by the different search engines\n",
    "doc_1 = Document(\n",
    "    did=\"doc_1\",\n",
    "    text=\"Significance Mimicry among bumble bees has driven them to diversify and converge in their color patterns, making them a replicate rich system for connecting genes to traits. Here, we discover that mimetic color variation in a bumble bee is driven by changes in Hox gene expression. Hox genes are master regulators of numerous segment specific morphologies and thus are some of the most conserved developmental genes across animals. In these bees, the posterior Hox gene Abd B is upregulated in a more anterior location to impart phenotypic change. This homeotic shift happens late in development, when nonspecific effects are minimized, thus availing these genes for color pattern diversification. Similar mimetic color patterns were inferred to use different mutations, suggesting diverse routes to mimicry. Natural phenotypic radiations, with their high diversity and convergence, are well suited for informing how genomic changes translate to natural phenotypic variation. New genomic tools enable discovery in such traditionally nonmodel systems. Here, we characterize the genomic basis of color pattern variation in bumble bees (Hymenoptera, Apidae, Bombus) a group that has undergone extensive convergence of setal color patterns as a result of Mullerian mimicry. In western North America, multiple species converge on local mimicry patterns through parallel shifts of midabdominal segments from red to black. Using genome wide association, we establish that a cis regulatory locus between the abdominal fate determining Hox genes, abd A and Abd B, controls the red black color switch in a western species, Bombus melanopygus. Gene expression analysis reveals distinct shifts in Abd B aligned with the duration of setal pigmentation at the pupal adult transition. This results in atypical anterior Abd B expression, a late developmental homeotic shift. Changing expression of Hox genes can have widespread effects, given their important role across segmental phenotypes; however, the late timing reduces this pleiotropy, making Hox genes suitable targets. Analysis of this locus across mimics and relatives reveals that other species follow independent genetic routes to obtain the same phenotypes.\",\n",
    ")\n",
    "doc_2 = Document(\n",
    "    did=\"doc_2\",\n",
    "    text=\"Bumble bees are declining worldwide, their vital ecosystem services are diminishing and underlying mechanisms are species specific and multifaceted. This has sparked an increase in long term assessments of historical collections that provide valuable information about population trends and shifts in distributions. However, museums specimens also contain important ecological information, including rarely measured morphological traits. Trait based assessments of museums specimens provide additional information on underlying mechanisms of population trends, by tracking changes over time. Here, we used museum specimens of four Bombus species, spanning a timeframe of 125 years to: (i) compare body size of declining and increasing species, (ii) assess intra specific trends over the last century, and (iii) investigate shifts in geographical distribution over time. We found that declining Bombus species were larger than increasing ones. All four species were smaller in current time than a century ago. Intra specific size declines were more pronounced for larger bodied species. With our sampling, declining and increasing species showed an upward shift in elevation, and declining species showed an additional geographic shift in recent times as compared to historic records. Intra specific body size declines may represent species adaptation to unfavorable environmental conditions, and may be a useful metric to complement traditional species vulnerability assessments. We highlight the utility of incorporating trait based assessments into future studies investigating species declines.\",\n",
    ")\n",
    "doc_3 = Document(\n",
    "    did=\"doc_3\",\n",
    "    text=\"Author(s) Rothman, Jason Advisor(s) McFrederick, Quinn Abstract: Bees are important insect pollinators in both agricultural and natural settings who may encounter toxicants while foraging on plants growing in contaminated soils. How these chemicals affect the bee microbiome, which confers many health benefits to the host, is an important but understudied aspect of pollinator health. Through a combination of 16S rRNA gene sequencing, LC MS metabolomics, ICP OES spectroscopy, quantitative PCR, culturing, microbiome manipulation, and whole organism exposure studies, I attempt to establish the effects that toxicants have on social bees and their associated microbes. The microbiome of animals has been shown to reduce metalloid toxicity, so I exposed microbiome inoculated or uninoculated bumble bees to 0.75 mg/L selenate and found that inoculated bees survive longer when compared to uninoculated bees. I also showed that selenate exposure altered the composition of the bumble bee microbiome and that the growth of two major gut symbionts Snodgrassella alvi and Lactobacillus bombicola was unaffected by this exposure. Due to the pervasiveness of environmental pollution in bee habitats, I exposed bumble bees to cadmium, copper, selenate, imidacloprid, and hydrogen peroxide and found that each of these compounds can be lethal to bees. I also showed that most of these chemicals can affect the diversity of the bee microbiome and that there is interstrain variation in toxicant tolerance genes in the major bee symbionts Snodgrassella alvi and Gilliamella apicola. As exposure to cadmium or selenate has been shown to affect animal associated microbes, I assayed the effects of these chemicals on honey bees and observed shifts in the bee microbiome at multiple timepoints. I also found that exposure to selenate and cadmium changes the overall bee metabolome and may cause oxidative damage to proteins and lipids. Lastly, I found that bee associated bacteria can bioaccumulate cadmium but generally not selenate. In this dissertation I demonstrated that bee associated bacteria are generally robust to toxicant exposure, but that chemicals can alter the composition of both bumble bee and honey bee microbiomes. I also show that toxicants affect bee metabolism, and that the bee microbiome plays an important role in maintaining host health when challenged with toxicants.\",\n",
    ")\n",
    "doc_4 = Document(\n",
    "    did=\"doc_4\",\n",
    "    text=\"abstract: Insects maximize their fitness by exhibiting predictable and adaptive seasonal patterns in response to changing environmental conditions. These seasonal patterns are often expressed even when insects are kept in captivity, suggesting they are functionally and evolutionary important. In this study we examined whether workers of the eusocial bumble bee Bombus impatiens maintained a seasonal signature when kept in captivity. We used an integrative approach and compared worker egg laying, ovarian activation, body size and mass, lipid content in the fat body, cold tolerance and expression of genes related to cold tolerance, metabolism, and stress throughout colony development. We found that bumble bee worker physiology and gene expression patterns shift from reproductive like to diapause like as the colony ages. Workers eclosing early in the colony cycle had increased egg laying and ovarian activation, and reduced cold tolerance, body size, mass, and lipid content in the fat body, in line with a reproductive like profile, while late eclosing workers exhibited the opposite characteristics. Furthermore, expression patterns of genes associated with reproduction and diapause differed between early and late eclosing workers, partially following the physiological patterns. We suggest that a seasonal signature, innate to individual workers, the queen or the colony is used by workers as a social cue determining the phenology of the colony and discuss possible implications for understanding reproductive division of labor in bumble bee colonies and the evolutionary divergence of female castes in the genus Bombus.\",\n",
    ")\n",
    "doc_5 = Document(\n",
    "    did=\"doc_5\",\n",
    "    text=\"ABSTRACT Insects maximize their fitness by exhibiting predictable and adaptive seasonal patterns in response to changing environmental conditions. These seasonal patterns are often expressed even when insects are kept in captivity, suggesting they are functionally and evolutionarily important. In this study, we examined whether workers of the eusocial bumble bee Bombus impatiens maintained a seasonal signature when kept in captivity. We used an integrative approach and compared worker egg laying, ovarian activation, body size and mass, lipid content in the fat body, cold tolerance and expression of genes related to cold tolerance, metabolism and stress throughout colony development. We found that bumble bee worker physiology and gene expression patterns shift from reproductive like to diapause like as the colony ages. Workers eclosing early in the colony cycle had increased egg laying and ovarian activation, and reduced cold tolerance, body size, mass and lipid content in the fat body, in line with a reproductive like profile, while late eclosing workers exhibited the opposite characteristics. Furthermore, expression patterns of genes associated with reproduction and diapause differed between early and late eclosing workers, partially following the physiological patterns. We suggest that a seasonal signature, innate to individual workers, the queen or the colony, is used by workers as a social cue determining the phenology of the colony and discuss possible implications for understanding reproductive division of labor in bumble bee colonies and the evolutionary divergence of female castes in the genus Bombus. Summary: Bumblebee workers exhibit a physiological signature (innate to workers, queen or the colony) corresponding to colony age with a shift towards a diapause like profile in late eclosing workers.\",\n",
    ")\n",
    "\n",
    "# Add the documents retrieved by the first search engine\n",
    "# Imagine that the first search engine retrieved the documents with the following ranking and scores:\n",
    "retrieved_by_search_engine_1 = [(doc_1, 0.9), (doc_5, 0.7), (doc_3, 0.2)]\n",
    "\n",
    "# In some cases, a search may not provide the score of the documents retrieved, just their rankings.\n",
    "# If that's the case, we can pass the list of documents in the same order as they were retrieved,\n",
    "# and their scores will be defined by their ranking.\n",
    "retrieved_by_search_engine_2 = [doc_2, doc_4, doc_5]\n",
    "\n",
    "query.add_retrieved_docs(retrieved_by_search_engine_1, agent=\"search_engine_1\")\n",
    "query.add_retrieved_docs(retrieved_by_search_engine_2, agent=\"search_engine_2\")\n",
    "\n",
    "# Evaluate the documents retrieved by the search engines for the query\n",
    "queries = evaluator.batch_evaluate([query])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see what the evaluations look like\n",
    "- Each query has a dictionary with the retrieved documents and their scores.\n",
    "- Each document may have been retrieved by more than one system, so we also keep a the score that the each system attributed to that document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Query text: \"bumble bee homeotic shift\"\n",
      "📚 5 documents retrieved by all agents\n",
      "--------------------------------------------------------------------------------\n",
      "📜 Document doc_1:\n",
      "\t📝 Text: Significance Mimicry among bumble bees has driven them to diversify and converge in their color patt (...)\n",
      "\t💭 LLM's reasoning: \"The document discusses the role of Hox genes in driving color pattern variation in bumble bees, spec\n",
      "\t🎯 Relevance: 3\n",
      "\t🕵️ Retrieved by: 1 agent(s): search_engine_1\n",
      "\t\t🔍 search_engine_1 score: 0.9\n",
      "--------------------------------------------------------------------------------\n",
      "📜 Document doc_5:\n",
      "\t📝 Text: ABSTRACT Insects maximize their fitness by exhibiting predictable and adaptive seasonal patterns in  (...)\n",
      "\t💭 LLM's reasoning: \"The document discusses the physiological changes in bumble bee workers and their seasonal patterns, \n",
      "\t🎯 Relevance: 2\n",
      "\t🕵️ Retrieved by: 2 agent(s): search_engine_1, search_engine_2\n",
      "\t\t🔍 search_engine_1 score: 0.7\n",
      "\t\t🔍 search_engine_2 score: 0.3333333333333333\n",
      "--------------------------------------------------------------------------------\n",
      "📜 Document doc_3:\n",
      "\t📝 Text: Author(s) Rothman, Jason Advisor(s) McFrederick, Quinn Abstract: Bees are important insect pollinato (...)\n",
      "\t💭 LLM's reasoning: \"The document discusses bumble bees and their microbiome in the context of toxicant exposure, which i\n",
      "\t🎯 Relevance: 1\n",
      "\t🕵️ Retrieved by: 1 agent(s): search_engine_1\n",
      "\t\t🔍 search_engine_1 score: 0.2\n",
      "--------------------------------------------------------------------------------\n",
      "📜 Document doc_2:\n",
      "\t📝 Text: Bumble bees are declining worldwide, their vital ecosystem services are diminishing and underlying m (...)\n",
      "\t💭 LLM's reasoning: \"The document discusses bumble bee population trends and shifts in distributions, which is related to\n",
      "\t🎯 Relevance: 1\n",
      "\t🕵️ Retrieved by: 1 agent(s): search_engine_2\n",
      "\t\t🔍 search_engine_2 score: 1.0\n",
      "--------------------------------------------------------------------------------\n",
      "📜 Document doc_4:\n",
      "\t📝 Text: abstract: Insects maximize their fitness by exhibiting predictable and adaptive seasonal patterns in (...)\n",
      "\t💭 LLM's reasoning: \"The document discusses various physiological and genetic aspects of bumble bees, particularly focusi\n",
      "\t🎯 Relevance: 1\n",
      "\t🕵️ Retrieved by: 1 agent(s): search_engine_2\n",
      "\t\t🔍 search_engine_2 score: 0.5\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = queries[0]\n",
    "print(f'🔎 Query text: \"{query.query}\"')\n",
    "print(f\"📚 {len(query.retrieved_docs)} documents retrieved by all agents\")\n",
    "print(\"-\" * 80)\n",
    "for document_id in query.retrieved_docs:\n",
    "    document = query.retrieved_docs[document_id]\n",
    "    retrieved_by = document.retrieved_by\n",
    "    explanation = document.evaluation.answer[\"explanation\"]\n",
    "    relevance = document.evaluation.answer[\"relevance\"]\n",
    "    print(f\"📜 Document {document_id}:\")\n",
    "    print(f\"\\t📝 Text: {document.text[:100]} (...)\")\n",
    "    print(f'\\t💭 LLM\\'s reasoning: \"{explanation[:100]}')\n",
    "    print(f\"\\t🎯 Relevance: {relevance}\")\n",
    "    print(f\"\\t🕵️ Retrieved by: {len(retrieved_by)} agent(s): {', '.join(retrieved_by.keys())}\")\n",
    "    for agent in retrieved_by:\n",
    "        print(f\"\\t\\t🔍 {agent} score: {retrieved_by[agent]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results\n",
    "\n",
    "### Formatting the results\n",
    "Most Information Retrieval evaluation frameworks rely on TREC-style evaluation. In this format, each query have its own set of relevant documents, called the qrels. Usually, a qrels object is treated as a dictionary, such as: \n",
    "```python\n",
    "qrels = {\n",
    "    \"query_id\": {\n",
    "        \"doc_id\": relevance,\n",
    "        \"doc_id\": relevance,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "Where `query_id` is the id of the query, `doc_id` is the id of the document that was considered for that query, and `relevance` is the relevance of the document to the query.\n",
    "\n",
    "On the other side, each retrieval system produces a ranking of documents in response to a query. The list of results for each query as returned by a retrieval system is usually called a `run`, and is also treated as a dictionary, such as:\n",
    "```python\n",
    "run_system_1 = {\n",
    "    \"query_id\": {\n",
    "        \"doc_id\": score,\n",
    "        \"doc_id\": score,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "Where `query_id` is the id of the query, `doc_id` is the id of the document that was considered for that query, and `score` is the score attributed to the document by the retrieval system.\n",
    "\n",
    "As in this example we only have one query, the run and qrels dictionaries will have only one key each.\n",
    "\n",
    "### Calculating the metrics\n",
    "\n",
    "Some of the most common metrics used in Information Retrieval are the Precision@K (P@K) and normalized Discounted Cumulative Gain (nDCG). These metrics are calculated by the `ir-measures` library, which takes the qrels and run dictionaries as input and returns the evaluation results.\n",
    "\n",
    "P@K (P@3 in our example, each system only retrieves 3 documents) measures, in the top-K results, the fraction of documents that are considered relevant (i.e, that have a relevance score greater than 0 in the qrels). It does not take into account the order of the documents in the ranking or the relevance score of the documents, only if they are above 0.\n",
    "\n",
    "nDCG, in the other hand, measures the quality of the ranking of the documents, according to an ideal ranking. In our example, as `doc_1` has a relevance score of 3 and `doc_5` a relevance score of 2, the ideal ranking would be [`doc_1`, `doc_5`, `doc_3`, `doc_4`, `doc_2`], with the last three being interchangeable. The nDCG can be interpreted as how close the ranking produced by the retrieval system is to this ideal ranking.\n",
    "\n",
    "\n",
    "For more information, please refer to the [ir-measures documentation](https://ir-measur.es/en/latest/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_measures\n",
    "from ir_measures import nDCG, MAP, P\n",
    "\n",
    "qrels = query.get_qrels()\n",
    "runs = query.get_runs()\n",
    "\n",
    "results_system_1 = ir_measures.calc_aggregate(\n",
    "    [P@3, nDCG], # The metrics we want to calculate. By adding the @K, we specify the cut-off for the metric.\n",
    "    qrels, # The relevance judgements generated by the evaluator.\n",
    "    runs[\"search_engine_1\"] # The ranking of the documents generated by the search engine.\n",
    ")\n",
    "results_system_2 = ir_measures.calc_aggregate(\n",
    "    [P@3, nDCG], # The metrics we want to calculate. By adding the @K, we specify the cut-off for the metric.\n",
    "    qrels, # The relevance judgements generated by the evaluator.\n",
    "    runs[\"search_engine_2\"] # The ranking of the documents generated by the search engine.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Search engine 1 rankings for query 🔎 \"bumble bee homeotic shift\":\n",
      "\t1️⃣ doc_1 (score = 0.9), relevance = 3\n",
      "\t2️⃣ doc_5 (score = 0.7), relevance = 2\n",
      "\t3️⃣ doc_3 (score = 0.2), relevance = 1\n",
      "📈 Metrics:\n",
      "\tP@3:  1.0000\n",
      "\tnDCG: 0.8535\n",
      "--------------------------------------------------------------------------------\n",
      "📊 Search engine 2 rankings for query 🔎 \"bumble bee homeotic shift\":\n",
      "\t1️⃣ doc_2 (score = 1.0), relevance = 1\n",
      "\t2️⃣ doc_4 (score = 0.5), relevance = 1\n",
      "\t3️⃣ doc_5 (score = 0.3333333333333333), relevance = 2\n",
      "📈 Metrics:\n",
      "\tP@3:  1.0000\n",
      "\tnDCG: 0.4715\n"
     ]
    }
   ],
   "source": [
    "# Let's sort the results of the search engines by their retrieval scores\n",
    "sorted_results_1 = sorted(runs[\"search_engine_1\"][\"query_1\"].items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_results_2 = sorted(runs[\"search_engine_2\"][\"query_1\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f'📊 Search engine 1 rankings for query 🔎 \"{query.query}\":')\n",
    "print(f\"\\t1️⃣ {sorted_results_1[0][0]} (score = {sorted_results_1[0][1]}), relevance = {qrels['query_1'][sorted_results_1[0][0]]}\")\n",
    "print(f\"\\t2️⃣ {sorted_results_1[1][0]} (score = {sorted_results_1[1][1]}), relevance = {qrels['query_1'][sorted_results_1[1][0]]}\")\n",
    "print(f\"\\t3️⃣ {sorted_results_1[2][0]} (score = {sorted_results_1[2][1]}), relevance = {qrels['query_1'][sorted_results_1[2][0]]}\")\n",
    "print(\"📈 Metrics:\")\n",
    "print(f\"\\tP@3:  {results_system_1[P@3]:.4f}\")\n",
    "print(f\"\\tnDCG: {results_system_1[nDCG]:.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(f'📊 Search engine 2 rankings for query 🔎 \"{query.query}\":')\n",
    "print(f\"\\t1️⃣ {sorted_results_2[0][0]} (score = {sorted_results_2[0][1]}), relevance = {qrels['query_1'][sorted_results_2[0][0]]}\")\n",
    "print(f\"\\t2️⃣ {sorted_results_2[1][0]} (score = {sorted_results_2[1][1]}), relevance = {qrels['query_1'][sorted_results_2[1][0]]}\")\n",
    "print(f\"\\t3️⃣ {sorted_results_2[2][0]} (score = {sorted_results_2[2][1]}), relevance = {qrels['query_1'][sorted_results_2[2][0]]}\")\n",
    "print(\"📈 Metrics:\")\n",
    "print(f\"\\tP@3:  {results_system_2[P@3]:.4f}\")\n",
    "print(f\"\\tnDCG: {results_system_2[nDCG]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results and varying the relevance threshold\n",
    "Note that, despite both systems having the same precision, the ranking that the first system produces is considerably better than the second one, with the documents retrieved being, on average, more relevant. This is better captured by the nDCG metric, which takes into account the relevance of the documents and their order in the ranking.\n",
    "\n",
    "One phenomenon that we have observed is that LLMs tend to _overestimate_ the quality of the retrieved documents when compared to human annotators. Therefore, one way around it is to define a tighter relevance threshold when evaluating the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Search engine 1 rankings for query 🔎 \"bumble bee homeotic shift\":\n",
      "\t1️⃣ doc_1 (score = 0.9), relevance = 3\n",
      "\t2️⃣ doc_5 (score = 0.7), relevance = 2\n",
      "\t3️⃣ doc_3 (score = 0.2), relevance = 0\n",
      "📈 Metrics:\n",
      "\tP@3:  0.6667\n",
      "\tnDCG: 1.0000\n",
      "--------------------------------------------------------------------------------\n",
      "📊 Search engine 2 rankings for query 🔎 \"bumble bee homeotic shift\":\n",
      "\t1️⃣ doc_2 (score = 1.0), relevance = 0\n",
      "\t2️⃣ doc_4 (score = 0.5), relevance = 0\n",
      "\t3️⃣ doc_5 (score = 0.3333333333333333), relevance = 2\n",
      "📈 Metrics:\n",
      "\tP@3:  0.3333\n",
      "\tnDCG: 0.2346\n"
     ]
    }
   ],
   "source": [
    "qrels = query.get_qrels(relevance_threshold=2) # Set the minimum relevance threshold to 2\n",
    "runs = query.get_runs()\n",
    "from ir_measures import P\n",
    "\n",
    "results_system_1 = ir_measures.calc_aggregate([P@3, nDCG], qrels, runs[\"search_engine_1\"])\n",
    "results_system_2 = ir_measures.calc_aggregate([P@3, nDCG], qrels, runs[\"search_engine_2\"])\n",
    "\n",
    "sorted_results_1 = sorted(runs[\"search_engine_1\"][\"query_1\"].items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_results_2 = sorted(runs[\"search_engine_2\"][\"query_1\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f'📊 Search engine 1 rankings for query 🔎 \"{query.query}\":')\n",
    "print(f\"\\t1️⃣ {sorted_results_1[0][0]} (score = {sorted_results_1[0][1]}), relevance = {qrels['query_1'][sorted_results_1[0][0]]}\")\n",
    "print(f\"\\t2️⃣ {sorted_results_1[1][0]} (score = {sorted_results_1[1][1]}), relevance = {qrels['query_1'][sorted_results_1[1][0]]}\")\n",
    "print(f\"\\t3️⃣ {sorted_results_1[2][0]} (score = {sorted_results_1[2][1]}), relevance = {qrels['query_1'][sorted_results_1[2][0]]}\")\n",
    "print(\"📈 Metrics:\")\n",
    "print(f\"\\tP@3:  {results_system_1[P@3]:.4f}\")\n",
    "print(f\"\\tnDCG: {results_system_1[nDCG]:.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(f'📊 Search engine 2 rankings for query 🔎 \"{query.query}\":')\n",
    "print(f\"\\t1️⃣ {sorted_results_2[0][0]} (score = {sorted_results_2[0][1]}), relevance = {qrels['query_1'][sorted_results_2[0][0]]}\")\n",
    "print(f\"\\t2️⃣ {sorted_results_2[1][0]} (score = {sorted_results_2[1][1]}), relevance = {qrels['query_1'][sorted_results_2[1][0]]}\")\n",
    "print(f\"\\t3️⃣ {sorted_results_2[2][0]} (score = {sorted_results_2[2][1]}), relevance = {qrels['query_1'][sorted_results_2[2][0]]}\")\n",
    "print(\"📈 Metrics:\")\n",
    "print(f\"\\tP@3:  {results_system_2[P@3]:.4f}\")\n",
    "print(f\"\\tnDCG: {results_system_2[nDCG]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the nDCG score for the first system is still 1.0, as it ranks the documents in their optimal order. However, now the P@3 values are more meaningful, as documents that were considered only slightly relevant by the LLM are now considered irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragelo38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
